# ğŸš¦ SÄ±nÄ±flandÄ±rma (Classification) AlgoritmalarÄ±

Derste gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z temel sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n kÄ±sa Ã¶zetleri, avantajlarÄ±

### SÄ±nÄ±flandÄ±rma TÃ¼rleri
1.  **Ä°kili SÄ±nÄ±flandÄ±rma (Binary Classification):** Ä°ki sÄ±nÄ±f etiketi vardÄ±r (DoÄŸru/YanlÄ±ÅŸ, Evet/HayÄ±r). Genellikle biri "normal" diÄŸeri "anormal" durumdur (Ã–rn: Kanser tespit edildi/edilmedi).
2.  **Ã‡ok SÄ±nÄ±flÄ± SÄ±nÄ±flandÄ±rma (Multiclass Classification):** Ä°kiden fazla sÄ±nÄ±f etiketi vardÄ±r. Normal/Anormal ayrÄ±mÄ± yoktur, Ã¶rnekler bir sÄ±nÄ±f aralÄ±ÄŸÄ±na girer.
3.  **Ã‡oklu Etiket SÄ±nÄ±flandÄ±rmasÄ± (Multi-label Classification):** Bir Ã¶rnek aynÄ± anda birden fazla sÄ±nÄ±fa ait olabilir. (Ã–rn: Bir haber hem "Teknoloji" hem "Son Haberler" kategorisinde olabilir).

## 1. Naive Bayes (NB)
**MantÄ±ÄŸÄ±:** "Saf" (Naive) denmesinin sebebi, verideki her Ã¶zelliÄŸin birbirinden baÄŸÄ±msÄ±z olduÄŸunu varsaymasÄ±dÄ±r (ki gerÃ§ek hayatta bu zordur).
* **KullanÄ±m:** Spam filtreleme, metin sÄ±nÄ±flandÄ±rma.
* **AvantajÄ±:** Az veriyle hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r, parametre tahmini kolaydÄ±r.

#### 2. Linear Discriminant Analysis (LDA)
* **MantÄ±k:** SÄ±nÄ±f koÅŸullu yoÄŸunluklarÄ± verilere uydurur ve Bayes kuralÄ±nÄ± uygular. DoÄŸrusal bir karar sÄ±nÄ±rÄ± oluÅŸturur.
* **Ã–zellik:** Veriyi daha dÃ¼ÅŸÃ¼k boyutlu bir uzaya yansÄ±tarak (boyut indirgeme) karmaÅŸÄ±klÄ±ÄŸÄ± ve hesaplama maliyetini azaltÄ±r.
* **VarsayÄ±m:** TÃ¼m sÄ±nÄ±flar aynÄ± kovaryans matrisini paylaÅŸÄ±r ve Gauss yoÄŸunluÄŸuna sahiptir.

## 3. Lojistik Regresyon (Logistic Regression)
**MantÄ±ÄŸÄ±:** AdÄ± regresyon olsa da bir sÄ±nÄ±flandÄ±rma algoritmasÄ±dÄ±r. Ã‡Ä±ktÄ±yÄ± 0 ile 1 arasÄ±nda bir olasÄ±lÄ±k deÄŸerine sÄ±kÄ±ÅŸtÄ±rmak iÃ§in **Sigmoid Fonksiyonu** kullanÄ±r.
* **FormÃ¼l:** $g(z) = \frac{1}{1 + e^{-z}}$.
* **Not:** Veriler doÄŸrusal (linear) ayrÄ±labiliyorsa Ã§ok iyi Ã§alÄ±ÅŸÄ±r.

## 4. K-En YakÄ±n KomÅŸu (KNN - K-Nearest Neighbors)
**MantÄ±ÄŸÄ±:** "Bana arkadaÅŸÄ±nÄ± sÃ¶yle, sana kim olduÄŸunu sÃ¶yleyeyim." Yeni bir veri geldiÄŸinde, ona en yakÄ±n **K** adet komÅŸusuna bakar. Ã‡oÄŸunluk hangi sÄ±nÄ±ftaysa o sÄ±nÄ±fa atar.
* Verileri kullanÄ±r ve benzerlik Ã¶lÃ§Ã¼tlerine (Ã¶rneÄŸin, **Ã–klid mesafe** fonksiyonu) gÃ¶re yeni veri noktalarÄ±nÄ± sÄ±nÄ±flandÄ±rÄ±r
* **Ã–zellik:** GÃ¼rÃ¼ltÃ¼lÃ¼ eÄŸitim verilerine karÅŸÄ± oldukÃ§a dayanÄ±klÄ±dÄ±r. Hem sÄ±nÄ±flandÄ±rma hem de regresyon iÃ§in kullanÄ±labilir.
* **Kritik Nokta:** `k` sayÄ±sÄ±nÄ± doÄŸru seÃ§mek Ã§ok Ã¶nemlidir.

## 5. Destek VektÃ¶r Makineleri (SVM)
**MantÄ±ÄŸÄ±:** SÄ±nÄ±flarÄ± birbirinden ayÄ±ran en geniÅŸ yolu (margin) bulmaya Ã§alÄ±ÅŸÄ±r. En uÃ§taki verilere "Destek VektÃ¶rÃ¼" denir.
* **Kernel Trick:** Veri doÄŸrusal ayrÄ±lmÄ±yorsa, veriyi Ã¼st boyutlara taÅŸÄ±yÄ±p orada ayÄ±rÄ±r (RBF, Polinom vb.).

#### 6. Decision Tree (DT) - Karar AÄŸacÄ±
* **MantÄ±k:** AÄŸacÄ± kÃ¶kten yapraklara doÄŸru sÄ±ralayarak sÄ±nÄ±flandÄ±rma yapar.
* **Algoritmalar:** ID3, C4.5, CART.
* **BÃ¶lme Kriterleri:**
    * **Entropi (Bilgi KazancÄ±):** $H(x) = -\sum p(x) \log_2 p(x)$
    * **Gini SafsÄ±zlÄ±ÄŸÄ±:** $Gini(E) = 1 - \sum p_i^2$.

#### 7. Random Forest (RF)
* **MantÄ±k:** "Topluluk" (Ensemble) tekniÄŸidir. Birden fazla karar aÄŸacÄ±nÄ± paralel olarak eÄŸitir ve Ã§oÄŸunluk oyunu (sÄ±nÄ±flandÄ±rma) veya ortalamayÄ± (regresyon) alÄ±r.
* **Avantaj:** Tek bir aÄŸaca gÃ¶re aÅŸÄ±rÄ± uyum (overfitting) sorununu azaltÄ±r ve doÄŸruluÄŸu artÄ±rÄ±r. Bootstrap aggregating (bagging) kullanÄ±r.

---

## B. Regresyon Analizi (Regression)
SÃ¼rekli bir sonuÃ§ deÄŸiÅŸkenini ($Y$) tahmin etmek iÃ§in kullanÄ±lÄ±r. SÄ±nÄ±flandÄ±rmadan farkÄ±, Ã§Ä±ktÄ±nÄ±n kategorik deÄŸil sayÄ±sal olmasÄ±dÄ±r.

### 1. Basit ve Ã‡oklu DoÄŸrusal Regresyon
* En uygun dÃ¼z Ã§izgiyi (regresyon doÄŸrusu) oluÅŸturur.
* **FormÃ¼l (Basit):** $y = a + bx + e$ (a: kesim noktasÄ±, b: eÄŸim, e: hata).
* **Ã‡oklu:** Birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸken ($x_1, x_2...$) varsa kullanÄ±lÄ±r.

### 2. Polinom Regresyonu
* Ä°liÅŸki doÄŸrusal deÄŸilse kullanÄ±lÄ±r. $x$'in $n$. dereceden polinomu alÄ±nÄ±r.
* **FormÃ¼l:** $y = b_0 + b_1x + b_2x^2 + ... + b_nx^n + e$.
